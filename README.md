# ğŸ“š Goodreads En PopÃ¼ler Kitaplar Veri Seti - Web Scraping Projesi

Bu proje, **Goodreads.com**'dan "Best Books Ever" listesindeki en popÃ¼ler kitaplarÄ±n bilgilerini otomatik olarak toplayan bir Python web scraping uygulamasÄ±dÄ±r. Kitap okurlarÄ±, yazarlar ve veri analisti adaylarÄ± iÃ§in zengin bir veri seti oluÅŸturur.

## ğŸ¯ Proje AmacÄ±

Goodreads'in "Best Books Ever" listesinden ÅŸu bilgileri toplayarak temizlenmiÅŸ bir veri seti oluÅŸturmak:
- ğŸ“– Kitap AdÄ± 
- âœï¸ Yazar AdÄ±
- â­ Ortalama Puan
- ğŸ“Š Toplam Puan SayÄ±sÄ±
- ğŸ’¬ Yorum SayÄ±sÄ±
- ğŸ”— Kitap URL'si
- ğŸ“ˆ Puan/Yorum OranÄ± (yeni Ã¶zellik)

## ğŸ› ï¸ Teknik Ã–zellikler

### KullanÄ±lan Teknolojiler
- **Python 3.8+**
- **requests**: HTTP istekleri iÃ§in
- **BeautifulSoup4**: HTML parsing iÃ§in
- **pandas**: Veri iÅŸleme ve analiz
- **tqdm**: Progress bar
- **lxml**: XML/HTML parser

### Scraping Ã–zellikleri
- âœ… **Ã‡oklu sayfa gezinme** (pagination)
- âœ… **Rate limiting** (istekler arasÄ± 1.5 saniye bekleme)
- âœ… **Hata yakalama ve logging**
- âœ… **robots.txt uyumlu** iÅŸlemler
- âœ… **Veri temizleme** ve doÄŸrulama
- âœ… **Progress tracking** (tqdm ile)
- âœ… **Checkpoint sistemi** (kesintiden sonra devam etme)
- âœ… **Resume Ã¶zelliÄŸi** (kaldÄ±ÄŸÄ±nÄ±z yerden baÅŸlayÄ±n)

## ğŸ“ Proje YapÄ±sÄ±

```
goodreads-scraper/
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ goodreads_scraper.py    # Ana scraper kodu
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ goodreads_top_1000_books.csv    # Toplanan veri seti
â”‚
â”œâ”€â”€ requirements.txt            # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ README.md                  # Bu dokÃ¼mantasyon
â””â”€â”€ scraper.log               # Ã‡alÄ±ÅŸma loglarÄ±
```

## ğŸš€ Kurulum ve KullanÄ±m

### 1. Projeyi Ä°ndirin
```bash
git clone <repository-url>
cd goodreads-scraper
```

### 2. Virtual Environment OluÅŸturun (Ã–nerilen)
```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
# veya
venv\Scripts\activate     # Windows
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
pip install -r requirements.txt
```

### 4. Scraper'Ä± Ã‡alÄ±ÅŸtÄ±rÄ±n

#### HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Interaktif)
```bash
python run_scraper.py
```

#### Command Line ile
```bash
cd src
python goodreads_scraper.py --pages 10 --delay 1.5
```

#### FarklÄ± Liste ile
```bash
cd src
python goodreads_scraper.py \
  --url "https://www.goodreads.com/list/show/3.Best_Science_Fiction_Fantasy_Books" \
  --pages 15 \
  --output "sci_fi_books.csv"
```

## âš™ï¸ KonfigÃ¼rasyon

### Command Line Parametreleri

| Parametre | AÃ§Ä±klama | VarsayÄ±lan | Ã–rnek |
|-----------|----------|------------|--------|
| `--pages` | KazÄ±nacak sayfa sayÄ±sÄ± | 10 | `--pages 5` |
| `--url` | Goodreads liste URL'si | Best Books Ever | `--url "https://..."` |
| `--delay` | Ä°stekler arasÄ± gecikme | 1.5s | `--delay 2.0` |
| `--output` | Ã‡Ä±ktÄ± dosyasÄ± adÄ± | goodreads_books.csv | `--output "my_books.csv"` |
| `--verbose` | DetaylÄ± loglar | KapalÄ± | `--verbose` |

### Ã–rnekler
```bash
# HÄ±zlÄ± test (5 sayfa)
python goodreads_scraper.py --pages 5

# BÃ¼yÃ¼k veri seti (20 sayfa, yavaÅŸ)  
python goodreads_scraper.py --pages 20 --delay 2.0

# Bilim kurgu kitaplarÄ±
python goodreads_scraper.py \
  --url "https://www.goodreads.com/list/show/3.Best_Science_Fiction_Fantasy_Books" \
  --pages 10 \
  --output "sci_fi_books.csv"
```

### Resume/Checkpoint Sistemi
```bash
# Mevcut checkpoint'leri gÃ¶rÃ¼ntÃ¼le
python goodreads_scraper.py --list-checkpoints

# Kesintiden sonra devam et
python goodreads_scraper.py --resume

# Belirli session'dan devam et
python goodreads_scraper.py --resume --session-id session_12345
```

ğŸ“– **DetaylÄ± kullanÄ±m iÃ§in**: [USAGE.md](USAGE.md) dosyasÄ±na bakÄ±n.

## ğŸ“Š Veri Temizleme SÃ¼reci

Script otomatik olarak ÅŸu temizleme iÅŸlemlerini yapar:

1. **Eksik BaÅŸlÄ±k KontrolÃ¼**: BaÅŸlÄ±ÄŸÄ± olmayan kitaplarÄ± kaldÄ±rÄ±r
2. **Duplikat Temizleme**: AynÄ± kitap-yazar kombinasyonlarÄ±nÄ± kaldÄ±rÄ±r
3. **Veri Tipi DÃ¶nÃ¼ÅŸÃ¼mÃ¼**: SayÄ±sal verileri int/float'a Ã§evirir
4. **Yeni Ã–zellik Ãœretme**: Puan/Yorum oranÄ± hesaplar
5. **SÄ±ralama**: KitaplarÄ± puan sayÄ±sÄ±na gÃ¶re sÄ±ralar

## ğŸ“ˆ Ã‡Ä±ktÄ± FormatÄ±

CSV dosyasÄ± ÅŸu kolonlarÄ± iÃ§erir:

| Kolon | AÃ§Ä±klama | Ã–rnek |
|-------|----------|--------|
| `title` | Kitap baÅŸlÄ±ÄŸÄ± | "To Kill a Mockingbird" |
| `author` | Yazar adÄ± | "Harper Lee" |
| `average_rating` | Ortalama puan | 4.27 |
| `ratings_count` | Toplam puan sayÄ±sÄ± | 5234567 |
| `reviews_count` | Yorum sayÄ±sÄ± | 234567 |
| `book_url` | Goodreads kitap linki | "https://www.goodreads.com/book/..." |
| `rating_to_review_ratio` | Puan/Yorum oranÄ± | 22.3 |

## ğŸš¦ Rate Limiting ve Etik KullanÄ±m

Bu proje Goodreads'in robots.txt dosyasÄ±na uygun ÅŸekilde tasarlanmÄ±ÅŸtÄ±r:

- âœ… Listopia sayfalarÄ± (`/list/show/`) robots.txt'de yasaklanmamÄ±ÅŸ
- â±ï¸ Ä°stekler arasÄ± 1.5 saniye bekleme sÃ¼resi
- ğŸ“ Respectful User-Agent kullanÄ±mÄ±
- ğŸ” Sadece halka aÃ§Ä±k listeleri hedefleme

## ğŸ”§ KarÅŸÄ±laÅŸÄ±lan Zorluklar ve Ã‡Ã¶zÃ¼mler

### 1. **Pagination Problemi**
**Problem**: Goodreads'in "Next" butonunu bulmak
**Ã‡Ã¶zÃ¼m**: Ã‡oklu CSS selector deneme ve regex kullanÄ±mÄ±

### 2. **Veri FormatÄ± TutarsÄ±zlÄ±klarÄ±**  
**Problem**: "1,234,567 ratings" formatÄ±ndaki metinlerden sayÄ± Ã§Ä±karma
**Ã‡Ã¶zÃ¼m**: Regex pattern'larÄ± ve string temizleme fonksiyonlarÄ±

### 3. **Request Blocking**
**Problem**: Ã‡ok hÄ±zlÄ± istek gÃ¶nderme
**Ã‡Ã¶zÃ¼m**: Rate limiting ve uygun User-Agent kullanÄ±mÄ±

## ğŸ“‹ Ã–rnek KullanÄ±m SenaryolarÄ±

1. **Kitap Ã–nerisi AlgoritmasÄ±**: En yÃ¼ksek puan/yorum oranÄ±na sahip kitaplarÄ± bulma
2. **Yazar Analizi**: En popÃ¼ler yazarlarÄ± belirleme  
3. **Trend Analizi**: Puan daÄŸÄ±lÄ±mlarÄ±nÄ± inceleme
4. **Veri GÃ¶rselleÅŸtirme**: Matplotlib/Seaborn ile grafik oluÅŸturma

## ğŸ¤ KatkÄ±da Bulunma

1. Fork'layÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Branch'inizi push edin (`git push origin feature/AmazingFeature`)
5. Pull Request oluÅŸturun

## âš ï¸ Yasal UyarÄ±lar

- Bu proje yalnÄ±zca eÄŸitim amaÃ§lÄ±dÄ±r
- Goodreads'in kullanÄ±m ÅŸartlarÄ±na ve robots.txt dosyasÄ±na saygÄ± gÃ¶sterir
- Veriler kiÅŸisel kullanÄ±m iÃ§indir, ticari amaÃ§larla kullanÄ±lmamalÄ±dÄ±r
- Web scraping yaparken her zaman hedef sitenin kurallarÄ±nÄ± kontrol edin

## ğŸ“ Ä°letiÅŸim

Herhangi bir soru veya Ã¶neri iÃ§in lÃ¼tfen issue aÃ§Ä±n.

---

**â­ Bu proje size yardÄ±mcÄ± olduysa, repository'yi yÄ±ldÄ±zlamayÄ± unutmayÄ±n!**