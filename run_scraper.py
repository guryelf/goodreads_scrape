#!/usr/bin/env python3
"""
Goodreads Scraper - HÄ±zlÄ± BaÅŸlangÄ±Ã§ Scripti
Bu script, gerekli kÃ¼tÃ¼phaneleri kontrol eder ve scraper'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r
"""

import subprocess
import sys
import os
from pathlib import Path

def check_requirements():
    """Gerekli kÃ¼tÃ¼phanelerin yÃ¼klenip yÃ¼klenmediÄŸini kontrol eder"""
    required_packages = [
        'requests', 'beautifulsoup4', 'pandas', 'lxml', 'numpy', 'tqdm'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
        except ImportError:
            missing_packages.append(package)
    
    return missing_packages

def install_requirements():
    """Eksik kÃ¼tÃ¼phaneleri yÃ¼kler"""
    print("ğŸ”§ Gerekli kÃ¼tÃ¼phaneler yÃ¼kleniyor...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
        print("âœ… KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ KÃ¼tÃ¼phane yÃ¼kleme hatasÄ±: {e}")
        return False

def run_scraper():
    """Ana scraper'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r"""
    print("\nğŸ“š Goodreads scraper baÅŸlatÄ±lÄ±yor...")
    
    # KullanÄ±cÄ±dan parametreler al
    pages = input("ï¿½ KaÃ§ sayfa iÅŸlensin? (varsayÄ±lan: 10): ").strip()
    if not pages:
        pages = "10"
    
    url = input("ğŸ”— FarklÄ± liste URL'si? (Enter = Best Books Ever): ").strip()
    if not url:
        url = "https://www.goodreads.com/list/show/1.Best_Books_Ever"
    
    delay = input("â±ï¸  Ä°stekler arasÄ± gecikme (saniye, varsayÄ±lan: 1.5): ").strip()
    if not delay:
        delay = "1.5"
    
    output = input("ï¿½ Ã‡Ä±ktÄ± dosyasÄ± adÄ± (varsayÄ±lan: goodreads_books.csv): ").strip()
    if not output:
        output = "goodreads_books.csv"
    
    print(f"\nğŸ¯ Hedef: {url}")
    print(f"ğŸ“„ {pages} sayfa (yaklaÅŸÄ±k {int(pages) * 100} kitap) iÅŸlenecek...")
    print(f"â±ï¸  Bu iÅŸlem {int(pages) * 0.5}-{int(pages)} dakika sÃ¼rebilir...\n")
    
    try:
        # src klasÃ¶rÃ¼ne geÃ§
        original_dir = os.getcwd()
        os.chdir('src')
        
        # Scraper'Ä± argÃ¼manlarla Ã§alÄ±ÅŸtÄ±r
        command = [
            sys.executable, "goodreads_scraper.py",
            "--pages", pages,
            "--url", url,
            "--delay", delay,
            "--output", output
        ]
        
        result = subprocess.run(command, capture_output=True, text=True)
        
        # Orijinal klasÃ¶re geri dÃ¶n
        os.chdir(original_dir)
        
        if result.returncode == 0:
            print("âœ… Scraping baÅŸarÄ±yla tamamlandÄ±!")
            print(f"ğŸ“Š Ã‡Ä±ktÄ±: {result.stdout}")
            
            # Veri dosyasÄ± oluÅŸtu mu kontrol et
            data_file = Path(f'data/{output}')
            if data_file.exists():
                print(f"\nğŸ“ Veri dosyasÄ± oluÅŸturuldu: {data_file}")
                print(f"ğŸ“ Dosya boyutu: {data_file.stat().st_size / 1024:.1f} KB")
            
        else:
            print("âŒ Scraping sÄ±rasÄ±nda hata oluÅŸtu:")
            print(result.stderr)
            
    except Exception as e:
        print(f"âŒ Script Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {e}")
        os.chdir(original_dir)

def show_project_info():
    """Proje bilgilerini gÃ¶sterir"""
    print("="*60)
    print("ğŸ“š GOODREADS WEB SCRAPER PROJESÄ°")
    print("="*60)
    print("ğŸ¯ AmaÃ§: Goodreads'ten en popÃ¼ler kitaplarÄ± toplamak")
    print("ğŸ“Š Hedef: ~1000 kitap verisi")
    print("ğŸ”§ Teknoloji: Python + BeautifulSoup + Pandas")
    print("ğŸ“ KlasÃ¶r yapÄ±sÄ±:")
    print("   â”œâ”€â”€ src/                 # Python kodlarÄ±")
    print("   â”œâ”€â”€ data/                # Toplanan veriler")
    print("   â”œâ”€â”€ requirements.txt     # Gerekli kÃ¼tÃ¼phaneler")
    print("   â””â”€â”€ README.md           # DokÃ¼mantasyon")
    print("="*60)

def main():
    """Ana fonksiyon"""
    show_project_info()
    
    # Gerekli kÃ¼tÃ¼phaneleri kontrol et
    missing = check_requirements()
    
    if missing:
        print(f"\nâš ï¸  Eksik kÃ¼tÃ¼phaneler tespit edildi: {', '.join(missing)}")
        
        install_choice = input("\nğŸ¤” Eksik kÃ¼tÃ¼phaneleri yÃ¼klemek ister misiniz? (y/n): ").lower().strip()
        
        if install_choice in ['y', 'yes', 'e', 'evet']:
            if not install_requirements():
                print("âŒ Kurulum baÅŸarÄ±sÄ±z. Manuel olarak 'pip install -r requirements.txt' Ã§alÄ±ÅŸtÄ±rÄ±n.")
                return
        else:
            print("âŒ Gerekli kÃ¼tÃ¼phaneler olmadan scraper Ã§alÄ±ÅŸmaz.")
            print("ğŸ’¡ YÃ¼kleme komutu: pip install -r requirements.txt")
            return
    
    else:
        print("\nâœ… TÃ¼m gerekli kÃ¼tÃ¼phaneler yÃ¼klÃ¼!")
    
    # Scraper'Ä± Ã§alÄ±ÅŸtÄ±r
    run_choice = input("\nğŸš€ Scraper'Ä± baÅŸlatmak ister misiniz? (y/n): ").lower().strip()
    
    if run_choice in ['y', 'yes', 'e', 'evet']:
        run_scraper()
        
        # Analiz Ã¶nerisi
        print("\nğŸ’¡ Ä°PUCU: Toplanan veriyi analiz etmek iÃ§in:")
        print("   cd src && python analyze_data.py")
        
    else:
        print("ğŸ‘‹ Ä°yi gÃ¼nler! HazÄ±r olduÄŸunuzda tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.")

if __name__ == "__main__":
    main()